#### Disaster Tweet Classifier: XLM‑RoBERTa‑Large for NLP Competition
Решение для соревнования Kaggle «Natural Language Processing with Disaster Tweets» (классификация твитов о катастрофах).

### Описание проекта
Модель на базе XLM‑RoBERTa‑Large для определения, относится ли твит к реальным катастрофам (target = 1) или нет (target = 0). Решение включает:

углублённую предобработку текста (очистка URL, упоминаний, спецсимволов);

балансировку классов через весовые коэффициенты;

тонкую настройку трансформера с ранней остановкой;

оценку по F1‑score и accuracy.

Ключевые особенности
Модель: xlm-roberta-large (многоязычный трансформер, 770M параметров).

Токенизация: длина последовательности — 96 токенов (обосновано анализом длин).

Баланс классов: учёт дисбаланса через class_weights.

Обучение:

7 эпох;

размер батча — 16 (с накоплением градиента: gradient_accumulation_steps=2);

скорость обучения — 2 × 10⁻⁵;

FP16‑ускорение.

Валидация:

стратифицированное разделение (test_size=0.2);

ранняя остановка (patience=3) по метрике F1.

Метрики: F1‑score и accuracy на валидации.

Результаты
Score на публичном лидерборде: 0.83634

Позиция в соревновании: 111‑е место из 772 команд

Метрики на валидации (примерные):

F1‑score: ~0.82–0.84;

Accuracy: ~0.85–0.87.

Архитектура решения
Предобработка текста:

Замена URL на URL.

Замена упоминаний (@user) на @USER.

Удаление спецсимволов, нормализация пробелов, приведение к нижнему регистру.

Токенизация:

max_length=96 (обосновано анализом длин токенов).

Пакетирование с паддингом и обрезкой.

Обучение:

Оптимизатор: AdamW.

Warmup: 10 % от шагов.

Веса классов: вычислены через compute_class_weight.

Инференс:

Предсказания на тестовом наборе.

Сохранение в submission_roberta.csv.
